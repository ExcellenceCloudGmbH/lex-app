CalculationModel:
  Import Path: from lex.lex_app.lex_models.CalculationModel import CalculationModel
  source code: |
    class CalculationModel(LexModel):
        IN_PROGRESS = 'IN_PROGRESS'
        ERROR = 'ERROR'
        SUCCESS = 'SUCCESS'
        NOT_CALCULATED = 'NOT_CALCULATED'
        ABORTED = 'ABORTED'
        STATUSES = [
        (IN_PROGRESS, 'IN_PROGRESS'),
        (ERROR, 'ERROR'),
        (SUCCESS, 'SUCCESS'),
        (NOT_CALCULATED, 'NOT_CALCULATED'),
        (ABORTED, 'ABORTED')
        ]
        
        is_calculated =  models.CharField(max_length=50, choices=STATUSES, default=NOT_CALCULATED)
        
        class Meta:
          abstract = True
        
        # This is the only thing that should be implemented, DON'T USE the implementation details
        @abstractmethod
        def calculate(self):
          pass
        
        # TODO: For the Celery task cases, this hook should be updated
        
        @hook(AFTER_UPDATE, on_commit=True)
        @hook(AFTER_CREATE, on_commit=True)
        def calculate_hook(self):
          try:
            if hasattr(self, 'is_atomic') and not self.is_atomic:
              # TODO: To fix with the correct type
              # update_calculation_status(self)
              self.calculate()
              self.is_calculated = self.SUCCESS
            else:
              with transaction.atomic():
                self.calculate()
                self.is_calculated = self.SUCCESS
          except Exception as e:
            self.is_calculated = self.ERROR
            raise e
          finally:
            self.save(skip_hooks=True)
            update_calculation_status(self)

  LexModel:
    Import Path: from lex.lex_app.lex_models.LexModel import LexModel
    source code: |
      class LexModel(LifecycleModel):
        
        created_by = models.TextField(null=True, blank=True, editable=False)
        edited_by = models.TextField(null=True, blank=True, editable=False)
        
        class Meta:
          abstract = True
        
        @hook(AFTER_UPDATE)
        def update_edited_by(self):
          context = context_id.get()
          if context and hasattr(context['request_obj'], 'auth'):
            self.edited_by = f"{context['request_obj'].auth['name']} ({context['request_obj'].auth['sub']})"
          else:
            self.edited_by = 'Initial Data Upload'
        
        @hook(AFTER_CREATE)
        def update_created_by(self):
          context = context_id.get()
          if context and hasattr(context['request_obj'], 'auth'):
            self.created_by = f"{context['request_obj'].auth['name']} ({context['request_obj'].auth['sub']})"
          else:
            self.created_by = 'Initial Data Upload'
LexLogger:
  Import Path: from lex.lex_app.LexLogger.LexLogger import LexLogger
  source code: |
    @LexSingleton
    class LexLogger:
      class MarkdownBuilder:
        lexLogger = None
        
        def __init__(self, level, flushing=True, **kwargs):
          self.kwargs = kwargs
          self.flushing = flushing
          self.level = level
          self.parts = []
          self.det = []
          self.content = self.parts
        
        def builder(self, level=LexLogLevel.INFO, flushing=True, **kwargs):
          self.kwargs = {**{key: value for key, value in kwargs.items()
            if key != "flushing" and key != "level" and key not in self.kwargs.keys()}, **self.kwargs}
          return self
        
        def details(self):
          self.content = self.det
          return self
        
        def normal(self):
          self.content = self.parts
          return self
        
        def _check_flush(self):
          if self.flushing:
            self.log()
          return self
        
        def add_heading(self, text: str, level: int = 1):
                                                  if 1 <= level <= 6:
                                                    self.content.append(f"{'#' * level} {text}\n")
                                                  return self._check_flush()
        
        def add_paragraph(self, text: str):
                                          """Add a paragraph."""
                                            self.content.append(f"{text}\n\n")
                                            return self._check_flush()
        
        def sleep(self, seconds):
          time.sleep(seconds)
          return self
        
        def add_colored_text(self, text, color="black"):
          self.content.append(f"<span style='color:{color}'>{text}</span>\n\n")
          return self._check_flush()
        
        def add_bold(self, text: str):
                                     """Add bold text."""
                                       self.content.append(f"**{text}** ")
                                       return self._check_flush()
        
        def add_table(self, data: dict):
                                      """Add a table from a dictionary. Keys are the headers, values are lists of column data."""
                                        headers = list(data.keys())
                                        rows = list(zip(*data.values()))
                                    
                                    # Add header row
                                        self.content.append(f"| {' | '.join(headers)} |\n")
                                        self.content.append(f"|{'|'.join([' --- ' for _ in headers])}|\n")
                                    
                                    # Add rows
                                        for row in rows:
                                          self.content.append(f"| {' | '.join(map(str, row))} |\n")
                                        self.content.append("\n")
                                        return self._check_flush()
        
        def add_df(self, dataframe, with_borders=True):
          if dataframe.empty:
            return self.add_paragraph("No data available")._check_flush()
          
          if with_borders:
            table_md = dataframe.to_markdown(index=False)
          else:
            table_md = dataframe.to_string(index=False)
          
          # Add to the content
          return self.add_paragraph(table_md)._check_flush()
        
        def add_df_from_string(self, string_data):
          data = ast.literal_eval(string_data)
          
          # If the data is a list of tuples/lists, infer the number of columns
          if isinstance(data, list) and len(data) > 0:
            # Infer the number of columns dynamically from the first row of the data
            num_columns = len(data[0])
            columns = [f"Column {i + 1}" for i in range(num_columns)]
            
            # Create a DataFrame
            df = pd.DataFrame(data, columns=columns)
            return self.add_table(df.to_dict())._check_flush()
          
          return self.add_paragraph("Invalid data format")._check_flush()
        
        def add_italic(self, text: str):
                                       """Add italic text."""
                                         self.content.append(f"*{text}*")
                                         return self._check_flush()
        
        def add_link(self, text: str, url: str):
                                               """Add a link."""
                                                 self.content.append(f"[{text}]({url})")
                                                 return self._check_flush()
        
        def add_list(self, items: list, ordered: bool = False):
                                                     """Add a list, either ordered (numbered) or unordered (bullets)."""
                                                       if ordered:
                                                         self.content.extend([f"{i + 1}. {item}" for i, item in enumerate(items)])
                                                       else:
                                                         self.content.extend([f"- {item}" for item in items])
                                                       self.content.append("\n")
                                                       return self._check_flush()
        
        def add_code_block(self, code: str, language: str = ""):
                                                          """Add a code block with optional language syntax highlighting."""
                                                            self.content.append(f"```{language}\n{code}\n```\n")
                                                            return self._check_flush()
        
        def add_horizontal_rule(self):
            """Add a horizontal rule."""
              self.content.append("---\n")
              return self._check_flush()
        
        def add_blockquote(self, text: str):
                                           """Add blockquote."""
                                             self.content.append(f"> {text}\n\n")
                                             return self._check_flush()
        
        def add_image(self, alt_text: str, url: str):
                                                    """Add an image."""
                                                      self.content.append(f"![{alt_text}]({url})\n\n")
                                                      return self._check_flush()
        
        def log(self, level: int = LexLogLevel.INFO):
                               message = self.__str__()
                               if not message:
                                 return
                               self.lexLogger.markdown(self.level, self.__str__(), **self.kwargs)
                               if self.content is self.parts:
                                 self.parts = []
                                 self.det = []
                                 self.content = self.parts
                               else:
                                 self.parts = []
                                 self.det = []
                                 self.content = self.det
                               
                               return self
        
        def __del__(self, **kwargs):
          self.log()
        
        def __str__(self):
            """Return the entire Markdown text as a string."""
              return "".join(self.parts)
        
        def details_to_str(self):
          return "".join(self.det)
        
        def return_markdown(self):
          return {**{WebSocketHandler.DJANGO_TO_REACT_MAPPER[key]: value for key, value in self.kwargs.items() if key != "flushing"}, WebSocketHandler.DJANGO_TO_REACT_MAPPER['details']: self.details_to_str(),
                                                                     WebSocketHandler.DJANGO_TO_REACT_MAPPER['message']: self.__str__(), WebSocketHandler.DJANGO_TO_REACT_MAPPER['level']: 'INFO'}
      
      def is_valid_markdown(self, message: str) -> bool:
                                             try:
                                               self.parser(message)
                                               return True
                                             except Exception as e:
                                               print(e)
                                               return False
      
      def __init__(self):
        self.logger = None
        self._initialize_logger()
        self.parser = mistune.create_markdown()
        self.MarkdownBuilder.lexLogger = self
      
      def _initialize_logger(self):
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(LexLogLevel.VERBOSE)
        
        # Add custom log level
        logging.addLevelName(LexLogLevel.VERBOSE, "VERBOSE")
        
        # Create handlers
        console_handler = logging.StreamHandler()
        file_handler = logging.FileHandler(settings.LOG_FILE_PATH)
        websocket_handler = WebSocketHandler()
        
        # Set levels for handlers
        console_handler.setLevel(LexLogLevel.WARNING)
        file_handler.setLevel(LexLogLevel.VERBOSE)
        websocket_handler.setLevel(LexLogLevel.VERBOSE)
        
        # Create formatters and add them to handlers
        # formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        formatter = logging.Formatter('%(message)s')
        console_handler.setFormatter(formatter)
        file_handler.setFormatter(formatter)
        websocket_handler.setFormatter(formatter)
        
        # Add handlers to the logger
        self.logger.addHandler(console_handler)
        self.logger.addHandler(file_handler)
        self.logger.addHandler(websocket_handler)
      
      def markdown_error(self, message):
        if not self.is_valid_markdown(message):
          return
        
        self.logger.error(message)
      
      def markdown(self, level, message, **kwargs):
        if not self.is_valid_markdown(message):
          return
        obj = CalculationLog.create(
        message=message,
        message_type=kwargs.get('message_type', "Progress"),
        trigger_name=kwargs.get('trigger_name', None),
        is_notification=kwargs.get('is_notification', False),
        )
        self.logger.log(level, message, extra={**kwargs, 'log_id': obj.id, 'calculation_id': obj.calculationId, 'class_name': obj.calculation_record, "trigger_name": obj.trigger_name, "method": obj.method})
      
      def builder(self, level=LexLogLevel.INFO, flushing=True, **kwargs):
        return self.MarkdownBuilder(level=level, flushing=flushing, **kwargs)
      
      def markdown_warning(self, message):
        if not self.is_valid_markdown(message):
          return
        
        self.logger.warning(message)
      
      def verbose(self, message):
        self.logger.log(LexLogLevel.VERBOSE, message)
      
      def debug(self, message):
        self.logger.debug(message)
      
      def info(self, message):
        self.logger.info(message)
      
      def warning(self, message):
        self.logger.warning(message)
      
      def error(self, message):
        self.logger.error(message)
      
      def critical(self, message):
        self.logger.critical(message)


XLSXField:
  Import Path: from lex.lex_app.rest_api.fields.XLSX_field import XLSXField
  source code: |
    class XLSXField(FileField):
      max_length = 300
      
      cell_format = '#,##0.00 ;[Red]-#,##0.00 ;_-* "-"??_-'
      cell_format_without_color = '#,##0.00 ;-#,##0.00 ;_-* "-"??_-'
      boolean_format = '[Green]"TRUE";[Red]"FALSE";[Red]"FALSE";[Red]"FALSE"'
      
      
      def get_number_of_rows_to_insert(self, sheet, index_len):
        max_len = 0
        for column_num in range(index_len + 1, sheet.max_column + 1):
          cell = sheet.cell(row=1, column=column_num)  # Adjust the row number to the row where you want to start splitting
          if cell.value:  # Check if the cell is not empty
            split_values = cell.value.split(".")
            max_len = max(max_len, len(split_values))
        
        return max_len
      
      def insert_rows_before_first_row(self, sheet, num_rows):
        sheet.insert_rows(1, amount=num_rows)
      
      def split_entries_in_sheet(self, sheet, number_of_inserted_rows, index_len):
        for column_num in range(index_len + 1, sheet.max_column + 1):  # Column F starts at index 6 (1-indexed)
          cell = sheet.cell(row=number_of_inserted_rows+1, column=column_num)  # Adjust the row number to the row where you want to start splitting
          if cell.value:  # Check if the cell is not empty
            split_values = cell.value.split(".")  # Split the entry at every "."
            first_row = 1  # First row to fill the split values
            for idx, split_value in enumerate(split_values):
              row_num = first_row + idx
              sheet.cell(row=row_num, column=column_num, value=split_value)
              # Bold the cell and add outside borders
              cell_to_format = sheet.cell(row=row_num, column=column_num)
              cell_to_format.font = Font(bold=True)
              cell_to_format.border = Border(top=Side(border_style='thin'),
              bottom=Side(border_style='thin'),
              left=Side(border_style='thin'),
              right=Side(border_style='thin'))
      
      def create_pivotable_row(self, sheet, index_len, number_of_rows_to_be_inserted, range_of_pivot_concatenation=None):
        for column_num in range(index_len + 1, sheet.max_column + 1):
          concatenated_value = ""
          for row_num in range_of_pivot_concatenation:
            cell = sheet.cell(row=row_num, column=column_num)
            if cell.value:
              concatenated_value += cell.value + " "
          sheet.cell(row=number_of_rows_to_be_inserted+1, column=column_num, value=concatenated_value.strip())
      
      def create_excel_file_from_dfs(self, path, data_frames, sheet_names=None, merge_cells=False, formats={}, comments={}, index=True, ranges_of_pivot_concatenation={'default': None}):
                                                                                                                                                                                      """
            :param path: file_path including file_name; if relative, will be saved under self.to+path
            :param data_frames: list of dataframes that will be inserted into an excel tab each
            :param sheet_names: list of sheet names corresponding to the data_frames
            :rtype: None
            """
        if sheet_names is None:
            sheet_names = ['Sheet']
        excel_file = BytesIO()
        writer = pd.ExcelWriter(excel_file, engine='xlsxwriter')
        df: pd.DataFrame
        idx_length = 0
        for df, sheet_name in zip(data_frames, sheet_names):
            if df is not None:
                if len(df) == 0:
                    df = df.append(pd.Series(), ignore_index=True)
                if index:
                    idx_length = df.index.nlevels
                df.to_excel(writer, sheet_name=sheet_name, merge_cells=merge_cells, freeze_panes=(1, idx_length),
                            index=index)

                worksheet = writer.sheets[sheet_name]  # pull worksheet object
                worksheet_comment = comments[sheet_name] if sheet_name in comments else None
                cell_formats = {}
                for format in formats:
                    cell_formats[format] = writer.book.add_format({'num_format': formats[format]})

                if index:
                    index_frame = df.index.to_frame()
                    for idx, col in enumerate(index_frame):  # loop through all columns
                        series = index_frame[col]
                        max_len = max((
                            series.astype(str).map(len).max(),  # len of largest item
                            len(str(series.name))  # len of column name/header
                        )) + 1  # adding a little extra space
                        if is_datetime(series):
                            max_len = 22
                        worksheet.set_column(idx, idx, max_len)  # set column width

                for idx, col in enumerate(df):  # loop through all columns
                    series = df[col]
                    if worksheet_comment is not None:
                        comment = worksheet_comment[col] if col in worksheet_comment else None
                        if comment is not None:
                            worksheet.write_comment(0, idx + idx_length, comment)

                    max_len = max((
                        series.astype(str).map(len).max(),  # len of largest item
                        len(str(series.name))  # len of column name/header
                    )) + 1  # adding a little extra space
                    worksheet.set_column(idx + idx_length, idx + idx_length, max_len)  # set column width
                    # set Cell format
                    if col in formats:
                        worksheet.set_column(idx + idx_length, idx + idx_length, max_len, cell_format=cell_formats[col])
                    elif is_datetime(df[col]):
                        pass
                    else:
                        worksheet.set_column(idx + idx_length, idx + idx_length, max_len,
                                             cell_format=writer.book.add_format({'num_format': XLSXField.cell_format}))
                # Add autofilter:
                if len(df.columns) > 0:
                    worksheet.autofilter(0, 0, len(df), idx_length + len(df.columns)-1)

        writer.save()
        writer.close()
        excel_file.seek(0)
        self.save(path, content=File(excel_file), save=False)
    
        return excel_file
  Example Usage: | 
      XLSXField.create_excel_file_from_dfs(<FileField Object>, path, data_frames, sheet_names)
    

LexLogLevel:
  Import Path: from lex.lex_app.LexLogger.LexLogLevel import LexLogLevel
  source code: |
    class LexLogLevel:
      VERBOSE = 5
      DEBUG = 10
      INFO = 20
      WARNING = 30
      ERROR = 40
      CRITICAL = 50

PrcoessAdminTest:
  Import Path: from lex.lex_app.tests.ProcessAdminTestCase import ProcessAdminTestCase
  source code: |
    class ProcessAdminTestCase(TestCase):
    # The ProcessAdminTestCase class is a custom test case class designed to facilitate testing in a Django application. It extends from unittest.TestCase and automates the setup and teardown of test data based on a JSON configuration. This class reads a JSON structure defining actions like create, update, and delete on Django models and executes these actions during the test setup phase.
    # Purpose: Extends `unittest.TestCase` to create a custom test case class that automates test data setup.
    
        def replace_tagged_parameters(self, object_parameters):
           # * Purpose: Processes parameters by replacing special tagged values with actual objects or parsed data.
           # * Functionality:
           #   - Iterates over each key-value pair in object_parameters.
           #   - If the value is a string and starts with:
           #     "tag:": Replaces it with an object from self.tagged_objects.
           #     "datetime:": Parses it into a datetime object.
           #   - Updates the parameter with the parsed value.
 
          for key in object_parameters:
              value: str = object_parameters[key]
              if isinstance(value, str):
                  parsed_value = value
                  if value.startswith("tag:"):
                      # Replace 'tag:<tag_name>' with the actual object from tagged_objects
                      parsed_value = self.tagged_objects[value.replace("tag:", "")]
                  elif value.startswith("datetime:"):
                      # Parse 'datetime:<date_string>' into a datetime object
                      parsed_value = dateutil.parser.parse(value.replace("datetime:", ""))
                  object_parameters[key] = parsed_value
          return object_parameters

    
        # test_path: An attribute that specifies the path to the test data JSON file. If not provided, it defaults to test_data.json in the same directory as the test class.
        test_path = None
    
     
        def setUp(self) -> None:
           # Purpose: Sets up the test environment by performing actions defined in the test data.
           # Functionality:
           #   Retrieves all models from the Django app specified in settings.repo_name.
           #   Initializes a timestamp and an empty dictionary for tagged objects.
           #   Loads test data using get_test_data().
           #   Iterates over each action in the test data and performs create, update, or delete operations.
           #     Create:
           #       Processes parameters and creates a new object.
           #       Stores the object in self.tagged_objects with the specified tag.
           #     Update:
           #       Processes filter parameters to find the object.
           #       Updates the object's attributes and saves it.
           #     Delete:
           #       Deletes objects matching the filter parameters.

            from datetime import datetime

            # Retrieve all models from the specified Django app
            generic_app_models = {
                f"{model.__name__}": model for model in
                set(apps.get_app_config(settings.repo_name).models.values())
            }

            self.t0 = datetime.now()  # Record the start time
            self.tagged_objects = {}  # Initialize a dictionary to store created objects

            test_data = self.get_test_data()  # Load test data from JSON

            # Iterate over each action in the test data
            for object in test_data:
                klass = generic_app_models[object['class']]  # Get the model class
                action = object['action']
                tag = object.get('tag', 'instance')  # Default tag if not provided

                if action == 'create':
                    # Replace tagged parameters
                    object['parameters'] = self.replace_tagged_parameters(object['parameters'])
                    # Create an instance of the model
                    self.tagged_objects[tag] = klass(**object['parameters'])
                    # Cache the action (thread-safe)
                    cache.set(threading.get_ident(), f"{object['class']}_{action}")
                    # Save the object to the database
                    self.tagged_objects[tag].save()

                elif action == 'update':
                    # Replace tagged filter parameters
                    object['filter_parameters'] = self.replace_tagged_parameters(object['filter_parmeters'])
                    # Retrieve the object to update
                    self.tagged_objects[tag] = klass.objects.filter(**object['filter_parameters']).first()
                    if self.tagged_objects[tag] is not None:
                        # Update the object's attributes
                        for key in object['parameters']:
                            setattr(self.tagged_objects[tag], key, object['parameters'][key])

                        # Cache the action with object primary key
                        cache.set(
                            threading.get_ident(),
                            f"{object['class']}_{action}_{self.tagged_objects[tag].pk}"
                        )
                        # Save the updated object
                        self.tagged_objects[tag].save()

                elif action == 'delete':
                    # Delete objects matching the filter parameters
                    klass.objects.filter(**object['filter_parameters']).delete()
    
        def tearDown(self) -> None:
            pass
    
        def get_test_data(self):
            # Purpose: Determines the path to the test data JSON file and loads it.
            # Functionality:
            #   If test_path is not set, defaults to test_data.json in the test class directory.
            #   If test_path is provided, constructs the path relative to PROJECT_ROOT.
            #   Calls get_test_data_from_path() to load and return the test data.

            if self.test_path is None:
                # Use default 'test_data.json' in the test class directory
                file = inspect.getfile(self.__class__)
                path = Path(file).parent
                clean_test_path = str(path) + os.sep + "test_data.json"
            else:
                # Use the provided 'test_path'
                clean_test_path = self.test_path.replace('/', os.sep)
                clean_test_path = os.getenv("PROJECT_ROOT") + os.sep + clean_test_path

            # Load test data from the JSON file
            test_data = self.get_test_data_from_path(clean_test_path)
            return test_data
    
        def get_test_data_from_path(self, path):
            # Purpose: Loads test data from the specified path, handling any nested subprocesses.
            # Functionality:
            #   Opens and reads the JSON file at the given path.
            #   Checks for any "subprocess" keys in the data and recursively loads additional test data.
            #   Flattens the potentially nested lists of test data into a single list.
            #   Returns the combined test data.

            with open(str(path), 'r') as f:
                test_data = json.loads(f.read())
                # Process any 'subprocess' entries recursively
                for index, object in enumerate(test_data):
                    if "subprocess" in object:
                        subprocess_path = object['subprocess'].replace('/', os.sep)
                        subprocess_path = os.getenv("PROJECT_ROOT") + os.sep + subprocess_path
                        sublist = self.get_test_data_from_path(subprocess_path)
                        test_data[index] = sublist

            # Flatten the list in case of nested lists from subprocesses
            flat_list = []
            for sublist in test_data:
                if isinstance(sublist, list):
                    flat_list.extend(sublist)
                else:
                    flat_list.append(sublist)
            return flat_list
    
        def get_classes(self, generic_app_models):
            # Purpose: Retrieves a set of all model classes involved in the test data.
            # Functionality:
            #   Loads the test data.
            #   Uses a set comprehension to collect unique model classes based on the "class" key in each test data object.

            test_data = self.get_test_data()
            # Collects all model classes used in the test data
            return set(generic_app_models[object['class']] for object in test_data)
    
        def check_if_all_models_are_empty(self, generic_app_models):
            # Purpose: Checks whether all involved model classes have no instances in the database.
            # Functionality:
            #   Iterates over each model class obtained from get_classes().
            #   Returns False immediately if any class has objects.
            #   Returns True only if all classes are empty.
 
            for klass in self.get_classes(generic_app_models):
                if klass.objects.all().count() > 0:
                    # If any model has objects, return False
                    return False
            # All models are empty
            return True
    
        def get_list_of_non_empty_models(self, generic_app_models):
            # Purpose: Provides a summary of models that have instances in the database.
            # Functionality:
            #   Iterates over each model class from get_classes().
            #   Counts the number of instances for each class.
            #   If a class has instances, adds it to the result dictionary with the count.
            #   Returns the dictionary of non-empty models.

            count_of_objects_in_non_empty_models = {}
            for klass in self.get_classes(generic_app_models):
                c = klass.objects.all().count()
                if c > 0:
                    # Add the class and count to the dictionary if not empty
                    count_of_objects_in_non_empty_models[str(klass)] = c
            return count_of_objects_in_non_empty_models
